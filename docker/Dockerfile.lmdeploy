FROM nvcr.io/nvidia/tritonserver:22.12-py3

RUN rm /etc/apt/sources.list.d/cuda*.list && apt-get update && apt-get install -y --no-install-recommends \
    rapidjson-dev libgoogle-glog-dev gdb python3.8-venv \
    && rm -rf /var/lib/apt/lists/* && cd /opt && python3 -m venv py38

RUN python3 -m pip install --no-cache-dir --upgrade pip setuptools==69.5.1 && \
    python3 -m pip install --no-cache-dir torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118 && \
    python3 -m pip install --no-cache-dir cmake packaging wheel

ENV NCCL_LAUNCH_MODE=GROUP

WORKDIR /opt/LMDeploy
ADD . /opt/LMDeploy
ARG SM="80"
RUN python3 -m pip install --no-cache-dir -r requirements.txt && \
    mkdir -p build && cd build && \
    cmake .. \
        -DCMAKE_BUILD_TYPE=RelWithDebInfo \
        -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \
        -DCMAKE_INSTALL_PREFIX=./install \
        -DBUILD_PY_FFI=ON \
        -DBUILD_MULTI_GPU=ON \
        -DCMAKE_CUDA_FLAGS="-lineinfo" \
        -DUSE_NVTX=ON \
        -DSM=${SM} -DCMAKE_CUDA_ARCHITECTURES=${SM} && \
    make -j$(nproc) && make install && \
    cd .. && \
    python3 -m pip install . && \
    # rm -rf build
    ls build
ENV LD_LIBRARY_PATH=/opt/LMDeploy/build/install/lib:$LD_LIBRARY_PATH

WORKDIR /workspace
ENV PROMETHEUS_MULTIPROC_DIR /workspace/metrics
RUN mkdir -p /workspace/metrics

CMD ["lmdeploy", "serve", "api_server", "./models/", "--server-name", "0.0.0.0", "--server-port", "80", "--session-len", "4096", "--cache-max-entry-count", "0.8", "--tp", "1"]
